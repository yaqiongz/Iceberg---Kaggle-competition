{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/yaqiongzhang/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Keras.\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, BatchNormalization\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "#define our model\n",
    "def getModel():\n",
    "    #Building the model\n",
    "    gmodel=Sequential()\n",
    "    #Conv Layer 1\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
    "    gmodel.add(BatchNormalization())\n",
    "    gmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "    \n",
    "    #Flatten the data for upcoming dense layers\n",
    "    gmodel.add(Flatten())\n",
    "\n",
    "    #Dense Layers\n",
    "    gmodel.add(Dense(512))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Dense Layer 2\n",
    "    gmodel.add(Dense(256))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Sigmoid Layer\n",
    "    gmodel.add(Dense(1))\n",
    "    gmodel.add(Activation('sigmoid'))\n",
    "\n",
    "    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    gmodel.compile(loss='binary_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    gmodel.summary()\n",
    "    return gmodel\n",
    "\n",
    "\n",
    "def get_callbacks(filepath, patience):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "file_path = \"model_weights.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load('X_train.npy')\n",
    "target_train=np.load('target_train.npy')\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train[:1604], train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 73, 73, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 73, 73, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 71, 71, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 31, 31, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               7373312   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 7,618,497\n",
      "Trainable params: 7,617,985\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaqiongzhang/anaconda/lib/python3.6/site-packages/keras/preprocessing/image.py:536: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn'tbeen fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/Users/yaqiongzhang/anaconda/lib/python3.6/site-packages/keras/preprocessing/image.py:544: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn'tbeen fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/60 [==============================] - 121s 2s/step - loss: 3.7944 - acc: 0.5813 - val_loss: 0.6803 - val_acc: 0.6025\n",
      "Epoch 2/100\n",
      "61/60 [==============================] - 122s 2s/step - loss: 1.3307 - acc: 0.6195 - val_loss: 0.7671 - val_acc: 0.4969\n",
      "Epoch 3/100\n",
      "61/60 [==============================] - 123s 2s/step - loss: 0.8152 - acc: 0.6530 - val_loss: 0.8429 - val_acc: 0.5901\n",
      "Epoch 4/100\n",
      "61/60 [==============================] - 124s 2s/step - loss: 0.6818 - acc: 0.6407 - val_loss: 1.2930 - val_acc: 0.5466\n",
      "Epoch 5/100\n",
      "61/60 [==============================] - 124s 2s/step - loss: 0.6829 - acc: 0.6558 - val_loss: 0.8873 - val_acc: 0.5466\n",
      "Epoch 6/100\n",
      "61/60 [==============================] - 125s 2s/step - loss: 0.6282 - acc: 0.6728 - val_loss: 1.9262 - val_acc: 0.5466\n",
      "Epoch 7/100\n",
      "61/60 [==============================] - 125s 2s/step - loss: 0.5787 - acc: 0.6891 - val_loss: 1.2704 - val_acc: 0.5404\n",
      "Epoch 8/100\n",
      "61/60 [==============================] - 605s 10s/step - loss: 0.5441 - acc: 0.6987 - val_loss: 0.5652 - val_acc: 0.6522\n",
      "Epoch 9/100\n",
      "61/60 [==============================] - 584s 10s/step - loss: 0.5385 - acc: 0.7206 - val_loss: 0.5913 - val_acc: 0.6335\n",
      "Epoch 10/100\n",
      "61/60 [==============================] - 573s 9s/step - loss: 0.5208 - acc: 0.7446 - val_loss: 0.4784 - val_acc: 0.7143\n",
      "Epoch 11/100\n",
      "61/60 [==============================] - 811s 13s/step - loss: 0.6391 - acc: 0.7105 - val_loss: 1.2660 - val_acc: 0.5466\n",
      "Epoch 12/100\n",
      "61/60 [==============================] - 597s 10s/step - loss: 0.5051 - acc: 0.7411 - val_loss: 1.4520 - val_acc: 0.5466\n",
      "Epoch 13/100\n",
      "61/60 [==============================] - 144s 2s/step - loss: 0.4669 - acc: 0.7622 - val_loss: 0.4675 - val_acc: 0.7267\n",
      "Epoch 14/100\n",
      "61/60 [==============================] - 169s 3s/step - loss: 0.5180 - acc: 0.7746 - val_loss: 0.7804 - val_acc: 0.6335\n",
      "Epoch 15/100\n",
      "61/60 [==============================] - 368s 6s/step - loss: 0.4498 - acc: 0.7842 - val_loss: 0.4822 - val_acc: 0.7702\n",
      "Epoch 16/100\n",
      "61/60 [==============================] - 984s 16s/step - loss: 0.4085 - acc: 0.8094 - val_loss: 0.4759 - val_acc: 0.7888\n",
      "Epoch 17/100\n",
      "61/60 [==============================] - 486s 8s/step - loss: 0.5832 - acc: 0.7507 - val_loss: 1.1763 - val_acc: 0.5590\n",
      "Epoch 18/100\n",
      "61/60 [==============================] - 166s 3s/step - loss: 0.5165 - acc: 0.7952 - val_loss: 1.0869 - val_acc: 0.5652\n",
      "Epoch 19/100\n",
      "61/60 [==============================] - 681s 11s/step - loss: 0.4495 - acc: 0.7991 - val_loss: 0.9483 - val_acc: 0.5963\n",
      "Epoch 20/100\n",
      "61/60 [==============================] - 1078s 18s/step - loss: 0.5413 - acc: 0.7910 - val_loss: 0.7659 - val_acc: 0.6646\n",
      "Epoch 21/100\n",
      "61/60 [==============================] - 387s 6s/step - loss: 0.4569 - acc: 0.8025 - val_loss: 0.7559 - val_acc: 0.6957\n",
      "Epoch 22/100\n",
      "61/60 [==============================] - 153s 3s/step - loss: 0.4889 - acc: 0.8231 - val_loss: 0.5758 - val_acc: 0.7516\n",
      "Epoch 23/100\n",
      "61/60 [==============================] - 410s 7s/step - loss: 0.4577 - acc: 0.7910 - val_loss: 0.4622 - val_acc: 0.7578\n",
      "Epoch 24/100\n",
      "61/60 [==============================] - 989s 16s/step - loss: 0.4202 - acc: 0.8081 - val_loss: 0.6446 - val_acc: 0.7143\n",
      "Epoch 25/100\n",
      "61/60 [==============================] - 567s 9s/step - loss: 0.3608 - acc: 0.8293 - val_loss: 0.3385 - val_acc: 0.8385\n",
      "Epoch 26/100\n",
      "61/60 [==============================] - 170s 3s/step - loss: 0.3483 - acc: 0.8334 - val_loss: 0.3575 - val_acc: 0.8075\n",
      "Epoch 27/100\n",
      "61/60 [==============================] - 612s 10s/step - loss: 0.3498 - acc: 0.8402 - val_loss: 0.4180 - val_acc: 0.8012\n",
      "Epoch 28/100\n",
      "61/60 [==============================] - 1081s 18s/step - loss: 0.4071 - acc: 0.8320 - val_loss: 0.3809 - val_acc: 0.8199\n",
      "Epoch 29/100\n",
      "61/60 [==============================] - 148s 2s/step - loss: 0.4068 - acc: 0.8361 - val_loss: 1.2692 - val_acc: 0.5466\n",
      "Epoch 30/100\n",
      "61/60 [==============================] - 378s 6s/step - loss: 0.4246 - acc: 0.8292 - val_loss: 2.0783 - val_acc: 0.5466\n",
      "Epoch 31/100\n",
      "61/60 [==============================] - 982s 16s/step - loss: 0.3953 - acc: 0.8374 - val_loss: 1.4089 - val_acc: 0.5466\n",
      "Epoch 32/100\n",
      "61/60 [==============================] - 657s 11s/step - loss: 0.4656 - acc: 0.8191 - val_loss: 6.7658 - val_acc: 0.5466\n",
      "Epoch 33/100\n",
      "61/60 [==============================] - 161s 3s/step - loss: 0.4519 - acc: 0.8107 - val_loss: 0.5176 - val_acc: 0.7764\n",
      "Epoch 34/100\n",
      "61/60 [==============================] - 492s 8s/step - loss: 0.3826 - acc: 0.8171 - val_loss: 0.3970 - val_acc: 0.8447\n",
      "Epoch 35/100\n",
      "61/60 [==============================] - 983s 16s/step - loss: 0.3938 - acc: 0.8129 - val_loss: 0.4052 - val_acc: 0.8323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1267e1550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "gmodel=getModel()\n",
    "gmodel.fit_generator(datagen.flow(X_train_cv, y_train_cv, batch_size=24),\n",
    "                    steps_per_epoch=len(X_train_cv) / 24, \n",
    "                    epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    validation_steps=len(X_valid) / 24,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
